# ê³ ê¸‰ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ

DanteLabs Agentic Schoolì˜ ì™„ì „ ìë™í™”ëœ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

## ğŸ“‹ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°œìš”

```
ì›ë³¸ ë°ì´í„°
    â†“
ğŸ” 1ï¸âƒ£ ë°ì´í„° í”„ë¡œíŒŒì¼ë§ (data-profiling)
    â†“
ğŸ“Š 2ï¸âƒ£ EDA ë¶„ì„ (data-profiling)
    â†“
âš™ï¸  3ï¸âƒ£ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (feature-engineering)
    â†“
âš–ï¸  4ï¸âƒ£ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (imbalance-handling)
    â†“
ğŸ¤– 5ï¸âƒ£ ëª¨ë¸ í•™ìŠµ (model-selection)
    â†“
ğŸ”§ 6ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (hyperparameter-tuning) â­ NEW
    â†“
ğŸ“ˆ 7ï¸âƒ£ ëª¨ë¸ í‰ê°€ (model-evaluation) â­ NEW
    â†“
ğŸ”¬ 8ï¸âƒ£ SHAP ë¶„ì„ (shap-analysis) â­ NEW
    â†“
ğŸ‘ï¸  9ï¸âƒ£ ëª¨ë¸ ëª¨ë‹ˆí„°ë§ (model-monitoring) â­ NEW
    â†“
ğŸš€ ğŸ”Ÿ ëª¨ë¸ ë°°í¬ (model-deployment) â­ NEW
    â†“
í”„ë¡œë•ì…˜ API ì„œë²„
```

## ğŸ¯ í”ŒëŸ¬ê·¸ì¸ ì „ì²´ ëª©ë¡ (9ê°œ)

### ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ (4ê°œ)

| # | í”ŒëŸ¬ê·¸ì¸ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
|---|---------|------|---------|
| 1 | **data-profiling** | ë°ì´í„° ë¶„ì„ | ìë™ EDA, A4 ë ˆí¬íŠ¸ |
| 2 | **feature-engineering** | íŠ¹ì„± ë³€í™˜ | ìŠ¤ì¼€ì¼ë§, ì‹œê°„ íŠ¹ì„± |
| 3 | **imbalance-handling** | ë¶ˆê· í˜• í•´ê²° | SMOTE, ADASYN |
| 4 | **model-selection** | ëª¨ë¸ í•™ìŠµ | XGBoost, LightGBM, RF |

### ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ (5ê°œ) â­ NEW

| # | í”ŒëŸ¬ê·¸ì¸ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
|---|---------|------|---------|
| 5 | **hyperparameter-tuning** | ìë™ ìµœì í™” | Optuna, TPE, Pruning |
| 6 | **model-evaluation** | ì„±ëŠ¥ ë¶„ì„ | Feature Importance, Learning Curves |
| 7 | **shap-analysis** | ì˜ˆì¸¡ ì„¤ëª… | SHAP Values, Waterfall Plot |
| 8 | **model-monitoring** | ì„±ëŠ¥ ì¶”ì  | Drift Detection, Alerts |
| 9 | **model-deployment** | í”„ë¡œë•ì…˜ ë°°í¬ | FastAPI, Docker, Swagger |

## ğŸš€ ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸ (ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° íƒì§€ ì˜ˆì œ)

### Step 0: í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

```bash
python scripts/init_project.py --name creditcard-fraud-detection
cp samples/datascience/data/raw/creditcard.csv \
   projects/creditcard-fraud-detection/data/raw/
```

### Step 1-4: ê¸°ë³¸ íŒŒì´í”„ë¼ì¸

```bash
# 1. í”„ë¡œíŒŒì¼ë§
/profile-data \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class"

# 2. EDA ë¶„ì„
/analyze-profile \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class"

# 3. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
/engineer-features \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class" \
  --time-features "hour,day,cyclical"

# 4. ë¶ˆê· í˜• ì²˜ë¦¬
/balance-data \
  --X-path "projects/creditcard-fraud-detection/data/processed/creditcard_processed_X.csv" \
  --y-path "projects/creditcard-fraud-detection/data/processed/creditcard_processed_y.csv" \
  --method smote \
  --ratio 0.1
```

### Step 5-10: ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ â­ NEW

```bash
# 5. ëª¨ë¸ í•™ìŠµ (ë² ì´ìŠ¤ë¼ì¸)
/train-model \
  --X-train-path "projects/creditcard-fraud-detection/data/processed/X_train_balanced.csv" \
  --y-train-path "projects/creditcard-fraud-detection/data/processed/y_train_balanced.csv" \
  --X-test-path "projects/creditcard-fraud-detection/data/processed/X_test.csv" \
  --y-test-path "projects/creditcard-fraud-detection/data/processed/y_test.csv" \
  --algorithm xgboost

# 6. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (50 trials, ì•½ 1ì‹œê°„)
/tune-hyperparameters \
  --X-train-path "projects/creditcard-fraud-detection/data/processed/X_train_balanced.csv" \
  --y-train-path "projects/creditcard-fraud-detection/data/processed/y_train_balanced.csv" \
  --algorithm xgboost \
  --metric pr_auc \
  --n-trials 50

# 7. ëª¨ë¸ í‰ê°€ (Feature Importance, Learning Curves)
/evaluate-model \
  --model-path "projects/creditcard-fraud-detection/outputs/models/xgboost_tuned_model.pkl" \
  --X-test-path "projects/creditcard-fraud-detection/data/processed/X_test.csv" \
  --y-test-path "projects/creditcard-fraud-detection/data/processed/y_test.csv"

# 8. SHAP ë¶„ì„ (ì˜ˆì¸¡ ì„¤ëª…)
/analyze-shap \
  --model-path "projects/creditcard-fraud-detection/outputs/models/xgboost_tuned_model.pkl" \
  --X-test-path "projects/creditcard-fraud-detection/data/processed/X_test.csv" \
  --y-test-path "projects/creditcard-fraud-detection/data/processed/y_test.csv" \
  --sample-size 1000

# 9. ëª¨ë¸ ëª¨ë‹ˆí„°ë§ (í”„ë¡œë•ì…˜ ë°ì´í„°ë¡œ)
/monitor-model \
  --model-path "projects/creditcard-fraud-detection/outputs/models/xgboost_tuned_model.pkl" \
  --reference-data "projects/creditcard-fraud-detection/data/processed/X_train_balanced.csv" \
  --current-data "projects/creditcard-fraud-detection/data/production/prod_2024_01.csv" \
  --target-column "Class"

# 10. API ë°°í¬
/deploy-model \
  --model-path "projects/creditcard-fraud-detection/outputs/models/xgboost_tuned_model.pkl" \
  --X-sample-path "projects/creditcard-fraud-detection/data/processed/X_train_balanced.csv"

# API ì„œë²„ ì‹¤í–‰
cd projects/creditcard-fraud-detection/deployment
uvicorn app:app --host 0.0.0.0 --port 8000
```

## ğŸ“Š ê° ë‹¨ê³„ë³„ ì¶œë ¥

### 1-4. ê¸°ë³¸ íŒŒì´í”„ë¼ì¸
```
projects/creditcard-fraud-detection/
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”œâ”€â”€ creditcard_profile_report.html     # í”„ë¡œíŒŒì¼ë§
â”‚   â”‚   â””â”€â”€ creditcard_eda_report.md           # EDA ë¶„ì„
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ xgboost_model.pkl                  # ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
â”‚       â””â”€â”€ preprocessing_pipeline.pkl
â””â”€â”€ data/
    â””â”€â”€ processed/
        â”œâ”€â”€ X_train_balanced.csv
        â”œâ”€â”€ y_train_balanced.csv
        â”œâ”€â”€ X_test.csv
        â””â”€â”€ y_test.csv
```

### 5-10. ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ â­ NEW
```
projects/creditcard-fraud-detection/
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ xgboost_tuned_model.pkl            # íŠœë‹ëœ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ xgboost_tuning_history.csv         # íŠœë‹ ì´ë ¥
â”‚   â”‚   â””â”€â”€ xgboost_best_params.txt            # ìµœì  íŒŒë¼ë¯¸í„°
â”‚   â”œâ”€â”€ evaluations/
â”‚   â”‚   â”œâ”€â”€ feature_importance.png             # íŠ¹ì„± ì¤‘ìš”ë„
â”‚   â”‚   â”œâ”€â”€ learning_curves.png                # í•™ìŠµ ê³¡ì„ 
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png               # Confusion Matrix
â”‚   â”‚   â””â”€â”€ evaluation_report.md               # í‰ê°€ ë¦¬í¬íŠ¸
â”‚   â”œâ”€â”€ shap/
â”‚   â”‚   â”œâ”€â”€ summary_plot.png                   # SHAP ìš”ì•½
â”‚   â”‚   â”œâ”€â”€ waterfall_plot.png                 # Waterfall
â”‚   â”‚   â”œâ”€â”€ force_plot.html                    # Force Plot
â”‚   â”‚   â””â”€â”€ shap_report.md                     # SHAP ë¦¬í¬íŠ¸
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ drift_summary.png                  # Drift ìš”ì•½
â”‚       â”œâ”€â”€ drift_report.csv                   # Drift ìƒì„¸
â”‚       â”œâ”€â”€ alerts.json                        # ì•Œë¦¼
â”‚       â””â”€â”€ monitoring_report.md               # ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸
â””â”€â”€ deployment/
    â”œâ”€â”€ app.py                                 # FastAPI ì„œë²„
    â”œâ”€â”€ Dockerfile                             # Docker ì´ë¯¸ì§€
    â”œâ”€â”€ docker-compose.yml                     # Docker Compose
    â”œâ”€â”€ requirements.txt                       # API ì˜ì¡´ì„±
    â””â”€â”€ README.md                              # ë°°í¬ ê°€ì´ë“œ
```

## ğŸ¯ ì„±ëŠ¥ ê°œì„  ê³¼ì •

### ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° íƒì§€ (284,807ê±´, 1:578 ë¶ˆê· í˜•)

| ë‹¨ê³„ | F1-Score | PR-AUC | ROC-AUC | ê°œì„  |
|-----|----------|--------|---------|------|
| **ë² ì´ìŠ¤ë¼ì¸** (XGBoost ê¸°ë³¸ê°’) | 0.83 | 0.87 | 0.976 | - |
| **+ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹** | 0.86 | 0.89 | 0.981 | +3.6% |
| **+ Feature Selection** | 0.87 | 0.90 | 0.983 | +4.8% |
| **+ Threshold ìµœì í™”** | 0.88 | 0.91 | 0.983 | +6.0% |

## ğŸ”§ í”ŒëŸ¬ê·¸ì¸ë³„ ìƒì„¸ ê°€ì´ë“œ

### 5ï¸âƒ£ hyperparameter-tuning

**ëª©ì **: ë² ì´ì§€ì•ˆ ìµœì í™”ë¡œ ìë™ íŠœë‹

**í•µì‹¬ ê¸°ëŠ¥**:
- Optuna TPE Sampler (Random Searchë³´ë‹¤ 10-100ë°° ë¹ ë¦„)
- Median Pruner (ì„±ëŠ¥ ë‚®ì€ ì‹œë„ ì¡°ê¸° ì¢…ë£Œ)
- Stratified K-Fold CV (5-Fold)

**ì˜ˆìƒ ì‹œê°„**: 50 trials = 1-2ì‹œê°„ (XGBoost)

**ì˜ˆìƒ ê°œì„ **: +2-4% F1-Score

### 6ï¸âƒ£ model-evaluation

**ëª©ì **: ëª¨ë¸ ì„±ëŠ¥ ì‹¬ì¸µ ë¶„ì„

**í•µì‹¬ ê¸°ëŠ¥**:
- Feature Importance (Top 20 ë³€ìˆ˜)
- Learning Curves (Train/Val ì†ì‹¤)
- Cross-Validation (K-Fold)
- Classification Report (Precision, Recall, F1)
- Confusion Matrix, ROC Curve, PR Curve

**ì¶œë ¥**: PNG ì‹œê°í™” + Markdown ë¦¬í¬íŠ¸

### 7ï¸âƒ£ shap-analysis

**ëª©ì **: ì˜ˆì¸¡ ì„¤ëª… ë° í•´ì„

**í•µì‹¬ ê¸°ëŠ¥**:
- SHAP Values ê³„ì‚° (TreeExplainer)
- Summary Plot (ì „ì²´ ë°ì´í„°)
- Waterfall Plot (ê°œë³„ ì˜ˆì¸¡)
- Force Plot (ì¸í„°ë™í‹°ë¸Œ)
- Dependence Plot (íŠ¹ì„± ì˜ì¡´ì„±)

**í™œìš©**:
- ëª¨ë¸ ì‹ ë¢°ì„± ê²€ì¦
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
- ê·œì œ ì¤€ìˆ˜ (ì„¤ëª… ê°€ëŠ¥í•œ AI)

### 8ï¸âƒ£ model-monitoring

**ëª©ì **: í”„ë¡œë•ì…˜ ëª¨ë¸ ì„±ëŠ¥ ì¶”ì 

**í•µì‹¬ ê¸°ëŠ¥**:
- Data Drift Detection (PSI, KS Test)
- Prediction Distribution Shift
- Performance Degradation Alert
- Real-time Metrics Tracking

**ì•Œë¦¼ ê¸°ì¤€**:
- PSI > 0.1: ì£¼ì˜
- PSI > 0.25: ì‹¬ê° (ì¬í•™ìŠµ í•„ìš”)
- KS Statistic > 0.1: Drift ë°œìƒ

### 9ï¸âƒ£ model-deployment

**ëª©ì **: í”„ë¡œë•ì…˜ API ë°°í¬

**í•µì‹¬ ê¸°ëŠ¥**:
- FastAPI REST API ìë™ ìƒì„±
- Pydantic ì…ë ¥ ê²€ì¦
- Swagger UI (ìë™ ë¬¸ì„œí™”)
- Docker ì»¨í…Œì´ë„ˆí™”
- Multi-worker ì§€ì›

**API Endpoints**:
- `GET /`: ì›°ì»´ ë©”ì‹œì§€
- `GET /health`: í—¬ìŠ¤ ì²´í¬
- `POST /predict`: ë‹¨ì¼ ì˜ˆì¸¡
- `POST /batch_predict`: ë°°ì¹˜ ì˜ˆì¸¡

**í”„ë¡œë•ì…˜ ì¤€ë¹„**:
- Health check
- Error handling
- Request validation
- API documentation
- Container support

## ğŸ” ì‹¤ì „ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì‹ ì† í”„ë¡œí† íƒ€ì… (1ì¼)

```bash
# 1-4. ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ (2ì‹œê°„)
/profile-data â†’ /analyze-profile â†’ /engineer-features â†’ /balance-data

# 5. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (10ë¶„)
/train-model --algorithm xgboost

# 6. ë¹ ë¥¸ íŠœë‹ (30ë¶„)
/tune-hyperparameters --n-trials 20 --timeout 1800

# 7. ê°„ë‹¨ í‰ê°€ (5ë¶„)
/evaluate-model
```

**ì´ ì†Œìš” ì‹œê°„**: ~3ì‹œê°„
**ì˜ˆìƒ ì„±ëŠ¥**: F1-Score 0.80-0.85

### ì‹œë‚˜ë¦¬ì˜¤ 2: í”„ë¡œë•ì…˜ ëª¨ë¸ (3ì¼)

```bash
# Day 1: ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ + ë² ì´ìŠ¤ë¼ì¸
/profile-data â†’ /analyze-profile â†’ /engineer-features â†’ /balance-data â†’ /train-model

# Day 2: ì •ë°€ íŠœë‹ + í‰ê°€
/tune-hyperparameters --n-trials 100  # 3-4ì‹œê°„
/evaluate-model
/analyze-shap

# Day 3: ë°°í¬ ì¤€ë¹„
/deploy-model
docker-compose up -d
/monitor-model (í”„ë¡œë•ì…˜ ë°ì´í„°ë¡œ)
```

**ì´ ì†Œìš” ì‹œê°„**: ~3ì¼
**ì˜ˆìƒ ì„±ëŠ¥**: F1-Score 0.85-0.90

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì—”í„°í”„ë¼ì´ì¦ˆ ì†”ë£¨ì…˜ (1ì£¼)

```bash
# Week 1 Plan:
# Mon-Tue: ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬
# Wed: ëª¨ë¸ í•™ìŠµ ë° íŠœë‹
# Thu: ëª¨ë¸ í‰ê°€ ë° SHAP ë¶„ì„
# Fri: ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ ì„¤ì •

# ì¶”ê°€ ì‘ì—…:
- Feature Engineering ë°˜ë³µ
- Ensemble ëª¨ë¸ (XGBoost + LightGBM + RF)
- A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
```

**ì´ ì†Œìš” ì‹œê°„**: ~1ì£¼
**ì˜ˆìƒ ì„±ëŠ¥**: F1-Score 0.90+
**ì‚°ì¶œë¬¼**: í”„ë¡œë•ì…˜ API + ëª¨ë‹ˆí„°ë§ + ë¬¸ì„œ

## ğŸ’¡ Best Practices

### 1. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìˆœì„œ

**í•„ìˆ˜ ìˆœì„œ**:
```
í”„ë¡œíŒŒì¼ë§ â†’ EDA â†’ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ â†’ ë¶ˆê· í˜• ì²˜ë¦¬ â†’ ëª¨ë¸ í•™ìŠµ
```

**ê¶Œì¥ ìˆœì„œ** (ê³ ê¸‰):
```
â†“ (ìœ„ ë‹¨ê³„ ì™„ë£Œ í›„)
ë² ì´ìŠ¤ë¼ì¸ í‰ê°€ â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ â†’ ìµœì¢… í‰ê°€ â†’ SHAP ë¶„ì„ â†’ ë°°í¬ â†’ ëª¨ë‹ˆí„°ë§
```

### 2. ì„±ëŠ¥ ìµœì í™” íŒ

| ëª©í‘œ | ë°©ë²• | ì˜ˆìƒ ê°œì„  |
|------|------|----------|
| **ë¹ ë¥¸ ì‹¤í—˜** | n-trials=20, timeout=30min | +1-2% |
| **ì •ë°€ íŠœë‹** | n-trials=100, pr_auc ìµœì í™” | +3-5% |
| **Ensemble** | XGBoost + LightGBM + RF | +5-8% |
| **Feature Selection** | SHAP ê¸°ë°˜ Top 20 ì„ íƒ | +2-3% |

### 3. í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ
- [ ] Feature Importance ë¶„ì„
- [ ] SHAP ë¶„ì„ (ì„¤ëª… ê°€ëŠ¥ì„±)
- [ ] Cross-Validation ê²€ì¦
- [ ] Test ë°ì´í„° ìµœì¢… í‰ê°€
- [ ] Docker ì»¨í…Œì´ë„ˆ ë¹Œë“œ
- [ ] API í…ŒìŠ¤íŠ¸ (ë‹¨ì¼ + ë°°ì¹˜)
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì • (PSI, KS)
- [ ] ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì •
- [ ] ë¬¸ì„œí™” (API, ëª¨ë¸ ì¹´ë“œ)

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ](./DATA_SCIENCE_PIPELINE.md)
- [í”„ë¡œì íŠ¸ êµ¬ì¡° ê°€ì´ë“œ](./PROJECTS.md)
- [hyperparameter-tuning í”ŒëŸ¬ê·¸ì¸](./plugins/data-science/hyperparameter-tuning/README.md)
- [model-evaluation í”ŒëŸ¬ê·¸ì¸](./plugins/data-science/model-evaluation/README.md)
- [shap-analysis í”ŒëŸ¬ê·¸ì¸](./plugins/data-science/shap-analysis/README.md)
- [model-monitoring í”ŒëŸ¬ê·¸ì¸](./plugins/data-science/model-monitoring/README.md)
- [model-deployment í”ŒëŸ¬ê·¸ì¸](./plugins/data-science/model-deployment/README.md)

## ğŸ“ í•™ìŠµ ê²½ë¡œ

### ì´ˆê¸‰: ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë§ˆìŠ¤í„°
1. ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ì´í•´
2. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•
3. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
4. ê¸°ë³¸ ëª¨ë¸ í•™ìŠµ

### ì¤‘ê¸‰: ì„±ëŠ¥ ìµœì í™”
5. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)
6. ëª¨ë¸ í‰ê°€ ë° ë¶„ì„
7. Feature Importance í•´ì„

### ê³ ê¸‰: í”„ë¡œë•ì…˜ ë°°í¬
8. SHAP ë¶„ì„ ë° ì„¤ëª…
9. ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ì „ëµ
10. API ë°°í¬ ë° ìš´ì˜

---

**ìƒì„±ì¼**: 2026-01-31
**ì‘ì„±ì**: Dante Labs
**ë²„ì „**: 2.0.0 (Advanced Pipeline)
**í”ŒëŸ¬ê·¸ì¸ ìˆ˜**: 9ê°œ (ê¸°ë³¸ 4 + ê³ ê¸‰ 5)
