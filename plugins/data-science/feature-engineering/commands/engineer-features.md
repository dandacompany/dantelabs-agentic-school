---
name: engineer-features
description: ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ ì™„ë£Œëœ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
arguments:
  - name: data-path
    description: ì›ë³¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    required: true
  - name: target-column
    description: íƒ€ê²Ÿ ë³€ìˆ˜ ì»¬ëŸ¼ëª… (ì „ì²˜ë¦¬ì—ì„œ ì œì™¸)
    required: false
  - name: scaling-strategy
    description: ìŠ¤ì¼€ì¼ë§ ì „ëµ (robust, standard, minmax)
    required: false
    default: "robust"
  - name: time-features
    description: ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ (comma-separated: hour,day,cyclical)
    required: false
  - name: output-dir
    description: ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬
    required: false
    default: "projects/{project-name}/data/processed"
---

# /engineer-features

ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ í•™ìŠµì— ì í•©í•œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## Usage

```bash
# ê¸°ë³¸ ì‚¬ìš©ë²• (RobustScaler)
/engineer-features \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv"

# íƒ€ê²Ÿ ì»¬ëŸ¼ ì§€ì • + ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ
/engineer-features \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class" \
  --time-features "hour,day,cyclical"

# StandardScaler ì‚¬ìš©
/engineer-features \
  --data-path "projects/my-analysis/data/raw/data.csv" \
  --scaling-strategy "standard"

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì •
/engineer-features \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class" \
  --output-dir "projects/creditcard-fraud-detection/data/processed"
```

## What This Command Does

### 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ ë° ë¶„ì„
- íŒŒì¼ ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸
- íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬
- ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ë³€ìˆ˜ ì‹ë³„

### 2. ìŠ¤ì¼€ì¼ë§ ì ìš©
**RobustScaler (ê¸°ë³¸ê°’, ê¶Œì¥)**:
- ì´ìƒì¹˜ì— ê°•ê±´ (median, IQR ì‚¬ìš©)
- ê¸ˆìœµ ë°ì´í„°, ì´ìƒì¹˜ ë§ì€ ë°ì´í„°ì— ì í•©
```python
from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()
```

**StandardScaler**:
- í‰ê·  0, ë¶„ì‚° 1ë¡œ ì •ê·œí™”
- ì •ê·œë¶„í¬ ê°€ì •, ì´ìƒì¹˜ ë¯¼ê°
```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
```

**MinMaxScaler**:
- 0-1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
- ì´ìƒì¹˜ì— ë§¤ìš° ë¯¼ê°
```python
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
```

### 3. ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ (ì„ íƒ)

**Time ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°**:
```python
# Hour ì¶”ì¶œ (0-23)
df['Hour'] = (df['Time'] / 3600) % 24

# Day ì¶”ì¶œ (0, 1, ...)
df['Day'] = (df['Time'] / 86400).astype(int)

# Cyclical Encoding (ì£¼ê¸°ì„± í‘œí˜„)
import numpy as np
df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)
df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)
```

**ì´ì **:
- ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ìº¡ì²˜ (ì‹¬ì•¼ ì‚¬ê¸° ê±°ë˜ ë“±)
- ì£¼ê¸°ì„± ë³´ì¡´ (23ì‹œì™€ 0ì‹œê°€ ê°€ê¹Œì›€ì„ ëª¨ë¸ì´ ì¸ì‹)

### 4. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì €ì¥
```python
import joblib

# íŒŒì´í”„ë¼ì¸ ì €ì¥ (ì¬ì‚¬ìš© ê°€ëŠ¥)
joblib.dump(scaler, 'projects/{project-name}/outputs/models/preprocessing_pipeline.pkl')

# ì‹ ê·œ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œ
scaler = joblib.load('projects/{project-name}/outputs/models/preprocessing_pipeline.pkl')
X_new_scaled = scaler.transform(X_new)  # fit ì—†ì´ transformë§Œ!
```

### 5. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
- **CSV í˜•ì‹**: `{dataset_name}_processed.csv`
- **ìœ„ì¹˜**: `data/processed/`
- **ë¶„ë¦¬ ì €ì¥**: X (íŠ¹ì„±), y (íƒ€ê²Ÿ)

## Output Structure

### ì „ì²˜ë¦¬ëœ ë°ì´í„°
```
projects/{project-name}/data/processed/
â”œâ”€â”€ creditcard_processed_X.csv  # íŠ¹ì„± ë°ì´í„°
â””â”€â”€ creditcard_processed_y.csv  # íƒ€ê²Ÿ ë°ì´í„°
```

### ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
```
projects/{project-name}/outputs/models/
â””â”€â”€ preprocessing_pipeline.pkl  # scikit-learn íŒŒì´í”„ë¼ì¸
```

### ë³€í™˜ ë¡œê·¸
```
projects/{project-name}/outputs/reports/
â””â”€â”€ creditcard_feature_engineering_log.md
```

**ë¡œê·¸ ì˜ˆì‹œ**:
```markdown
# íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ë¡œê·¸

**ìƒì„±ì¼**: 2026-01-31 08:30
**ì›ë³¸ ë°ì´í„°**: creditcard.csv (284,807ê±´, 31ê°œ íŠ¹ì„±)

## ì ìš©ëœ ë³€í™˜

### 1. ìŠ¤ì¼€ì¼ë§ (RobustScaler)
- **ëŒ€ìƒ ë³€ìˆ˜**: Amount
- **ë³€í™˜ í›„ ì»¬ëŸ¼**: Amount_scaled
- **ì›ë³¸ ì»¬ëŸ¼ ì œê±°**: âœ“
- **ì´ìœ **: ì´ìƒì¹˜ì— ê°•ê±´, ê·¹ë‹¨ê°’ ì¡´ì¬

### 2. ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ
- **ì›ë³¸**: Time (ì´ˆ ë‹¨ìœ„ ê²½ê³¼ ì‹œê°„)
- **ìƒì„±ëœ íŠ¹ì„±**:
  - Hour (0-23): ì‹œê°„ëŒ€ ì‹ë³„
  - Day (0, 1): ë‚ ì§œ êµ¬ë¶„
  - Hour_sin, Hour_cos: ì£¼ê¸°ì„± ì¸ì½”ë”©
- **ì›ë³¸ ì»¬ëŸ¼ ì œê±°**: âœ“

### 3. ë³€ìˆ˜ ìš”ì•½
- **ì›ë³¸ íŠ¹ì„±**: 31ê°œ
- **ìµœì¢… íŠ¹ì„±**: 34ê°œ (+3ê°œ)
- **ì œê±°ëœ íŠ¹ì„±**: 2ê°œ (Time, Amount)
- **ì¶”ê°€ëœ íŠ¹ì„±**: 5ê°œ (Amount_scaled, Hour, Day, Hour_sin, Hour_cos)

### 4. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- **ì €ì¥ ìœ„ì¹˜**: projects/{project-name}/outputs/models/preprocessing_pipeline.pkl
- **ì¬ì‚¬ìš© ë°©ë²•**:
  ```python
  import joblib
  scaler = joblib.load('projects/{project-name}/outputs/models/preprocessing_pipeline.pkl')
  X_new_scaled = scaler.transform(X_new)
  ```

## ë‹¤ìŒ ë‹¨ê³„
- `/handle-imbalance`: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (SMOTE)
- `/train-models`: ëª¨ë¸ í•™ìŠµ
```

## Examples

### Example 1: ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° íƒì§€
```bash
/engineer-features \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class" \
  --time-features "hour,day,cyclical" \
  --scaling-strategy "robust"
```

**ê²°ê³¼**:
- Amount â†’ Amount_scaled (RobustScaler)
- Time â†’ Hour, Day, Hour_sin, Hour_cos
- V1-V28: ê·¸ëŒ€ë¡œ ìœ ì§€ (ì´ë¯¸ PCA ì •ê·œí™”ë¨)

### Example 2: ê³ ê° ì´íƒˆ ì˜ˆì¸¡
```bash
/engineer-features \
  --data-path "projects/customer-churn-prediction/data/raw/churn.csv" \
  --target-column "Churn" \
  --scaling-strategy "standard"
```

**ê²°ê³¼**:
- tenure, MonthlyCharges â†’ StandardScaler
- gender, Contract â†’ One-hot encoding (ìë™ ê°ì§€)

### Example 3: ì»¤ìŠ¤í…€ ì¶œë ¥ ê²½ë¡œ
```bash
/engineer-features \
  --data-path "projects/my-experiment/data/raw/data.csv" \
  --output-dir "projects/my-experiment/experiment_1/processed"
```

## Scaling Strategies Comparison

| ì „ëµ | ì‚¬ìš© ì‹œê¸° | ì¥ì  | ë‹¨ì  |
|------|---------|------|------|
| **RobustScaler** | ì´ìƒì¹˜ ë§ìŒ | ì´ìƒì¹˜ ì˜í–¥ ìµœì†Œ | - |
| **StandardScaler** | ì •ê·œë¶„í¬ | ë„ë¦¬ ì‚¬ìš©, í‘œì¤€ | ì´ìƒì¹˜ ë¯¼ê° |
| **MinMaxScaler** | 0-1 í•„ìš” | ì§ê´€ì  | ì´ìƒì¹˜ ë§¤ìš° ë¯¼ê° |

**ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° íƒì§€**: RobustScaler (Amountì— ê·¹ë‹¨ê°’ ì¡´ì¬)

## Time Features Benefits

### ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ìº¡ì²˜
```python
# ì‹œê°„ëŒ€ë³„ ì‚¬ê¸° ë¹„ìœ¨
fraud_by_hour = df.groupby('Hour')['Class'].mean()
# â†’ ì‹¬ì•¼(0-6ì‹œ)ì— ì‚¬ê¸° ì§‘ì¤‘ ê°€ëŠ¥ì„±
```

### Cyclical Encoding í•„ìš”ì„±
- ë‹¨ìˆœ Hour (0-23)ë§Œ ì‚¬ìš© ì‹œ:
  - 23ì‹œì™€ 0ì‹œê°€ ë©€ë¦¬ ë–¨ì–´ì§„ ê²ƒìœ¼ë¡œ ì¸ì‹ (ì°¨ì´ 23)
  - ì‹¤ì œë¡œëŠ” 1ì‹œê°„ ì°¨ì´ì¼ ë¿

- Cyclical Encoding ì‚¬ìš© ì‹œ:
  ```python
  Hour_sin = sin(2Ï€ Ã— Hour / 24)
  Hour_cos = cos(2Ï€ Ã— Hour / 24)
  # â†’ 23ì‹œì™€ 0ì‹œê°€ ê°€ê¹Œìš´ ê²ƒìœ¼ë¡œ ì¸ì‹
  ```

## Performance Tips

### ëŒ€ìš©ëŸ‰ ë°ì´í„°
- ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬: `pd.read_csv(chunksize=10000)`
- Sparse í˜•ì‹ ì‚¬ìš©: One-hot encoding ì‹œ
- Dask ì‚¬ìš©: ë©”ëª¨ë¦¬ ì´ˆê³¼ ì‹œ

### íŒŒì´í”„ë¼ì¸ ì¬ì‚¬ìš©
```python
# í•™ìŠµ ë°ì´í„°ë¡œ fit
from sklearn.pipeline import Pipeline
pipeline = Pipeline([
    ('scaler', RobustScaler()),
])
pipeline.fit(X_train)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” transformë§Œ
X_test_scaled = pipeline.transform(X_test)

# í”„ë¡œë•ì…˜ ë°°í¬
joblib.dump(pipeline, 'projects/{project-name}/outputs/models/model.pkl')
```

## Related Commands

- `/profile-data`: ì „ì²˜ë¦¬ ì „ ë°ì´í„° ë¶„ì„
- `/analyze-profile`: ì „ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½
- `/handle-imbalance`: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (ë‹¤ìŒ ë‹¨ê³„)
- `/train-models`: ëª¨ë¸ í•™ìŠµ (ì „ì²˜ë¦¬ í›„)

## Agents Used

- `feature-engineer` (í•„ìˆ˜): ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§

## Notes

âš ï¸ **ì£¼ì˜ì‚¬í•­**:
- Train/Test ë¶„ë¦¬ í›„ ì „ì²˜ë¦¬ (Data leakage ë°©ì§€)
- Test ë°ì´í„°ëŠ” transformë§Œ (fit ê¸ˆì§€)
- íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì „ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ

ğŸ’¡ **íŒ**:
- EDA ë ˆí¬íŠ¸(`/analyze-profile`) ë¨¼ì € í™•ì¸í•˜ì—¬ ì „ëµ ìˆ˜ë¦½
- ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì €ì¥í•˜ì—¬ ì¬ì‚¬ìš©
- ì „ì²˜ë¦¬ í›„ ë‹¤ì‹œ `/profile-data` ì‹¤í–‰í•˜ì—¬ ê²€ì¦
