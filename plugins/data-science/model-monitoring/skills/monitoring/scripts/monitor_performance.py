#!/usr/bin/env python3
"""
ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ ì¶”ì í•˜ê³  ë°ì´í„° ë“œë¦¬í”„íŠ¸ë¥¼ íƒì§€í•©ë‹ˆë‹¤.

ì„¤ì¹˜:
    cd plugins/model-monitoring/skills/monitoring
    uv pip install -r requirements.txt

ì‚¬ìš©ë²•:
    python monitor_performance.py --model-path "./models/model.pkl" --reference-data "./data/train.csv" --current-data "./data/prod_2024.csv" --target-column "Class"
    python monitor_performance.py --model-path "./models/model.pkl" --reference-data "./data/train.csv" --current-data "./data/prod_2024.csv" --target-column "Class" --alert-threshold 0.1

í•„ìš” íŒ¨í‚¤ì§€:
    - pandas
    - evidently
    - matplotlib
    - scipy
"""

import argparse
import json
import os
import sys
import warnings
from datetime import datetime
from pathlib import Path

import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    mean_absolute_error,
    mean_squared_error,
    precision_score,
    r2_score,
    recall_score,
)

warnings.filterwarnings('ignore')


def print_header(text):
    """í—¤ë” ì¶œë ¥"""
    print(f"\n{'=' * 60}")
    print(text)
    print('=' * 60)


def print_section(text):
    """ì„¹ì…˜ ì¶œë ¥"""
    print(f"\n{'-' * 60}")
    print(text)
    print('-' * 60)


def load_data(data_path, target_column=None):
    """ë°ì´í„° ë¡œë“œ"""
    print(f"\nâœ“ ë°ì´í„° ë¡œë“œ ì¤‘: {data_path}")

    file_ext = Path(data_path).suffix.lower()

    if file_ext == '.csv':
        df = pd.read_csv(data_path)
    elif file_ext in ['.xlsx', '.xls']:
        df = pd.read_excel(data_path)
    elif file_ext == '.parquet':
        df = pd.read_parquet(data_path)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")

    if target_column and target_column in df.columns:
        X = df.drop(columns=[target_column])
        y = df[target_column]
        print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê±´, {len(X.columns)}ê°œ íŠ¹ì„±, íƒ€ê²Ÿ ìˆìŒ")
        return X, y, df
    else:
        print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê±´, {len(df.columns)}ê°œ íŠ¹ì„±, íƒ€ê²Ÿ ì—†ìŒ")
        return df, None, df


def load_model(model_path):
    """ëª¨ë¸ ë¡œë“œ"""
    print(f"\nâœ“ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")

    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

    model = joblib.load(model_path)
    print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {type(model).__name__}")

    return model


def calculate_psi(reference, current, bins=10):
    """PSI (Population Stability Index) ê³„ì‚°"""
    # ì—°ì†í˜• ë³€ìˆ˜ë¥¼ binning
    breakpoints = np.percentile(reference, np.linspace(0, 100, bins + 1))
    breakpoints = np.unique(breakpoints)

    ref_counts, _ = np.histogram(reference, bins=breakpoints)
    cur_counts, _ = np.histogram(current, bins=breakpoints)

    # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    ref_percents = (ref_counts + 1) / (len(reference) + bins)
    cur_percents = (cur_counts + 1) / (len(current) + bins)

    psi = np.sum((cur_percents - ref_percents) * np.log(cur_percents / ref_percents))

    return psi


def calculate_ks_statistic(reference, current):
    """KS (Kolmogorov-Smirnov) í†µê³„ëŸ‰ ê³„ì‚°"""
    ks_stat, p_value = stats.ks_2samp(reference, current)
    return ks_stat, p_value


def detect_data_drift(X_ref, X_cur, output_dir, threshold=0.1):
    """ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€"""
    print_section("ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€")

    drift_results = []

    for col in X_ref.columns:
        if col not in X_cur.columns:
            print(f"âš ï¸  '{col}' ì»¬ëŸ¼ì´ í˜„ì¬ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            continue

        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì²˜ë¦¬
        if not np.issubdtype(X_ref[col].dtype, np.number):
            continue

        ref_data = X_ref[col].dropna()
        cur_data = X_cur[col].dropna()

        # PSI ê³„ì‚°
        psi = calculate_psi(ref_data.values, cur_data.values)

        # KS í†µê³„ëŸ‰ ê³„ì‚°
        ks_stat, p_value = calculate_ks_statistic(ref_data.values, cur_data.values)

        # ë“œë¦¬í”„íŠ¸ íŒì •
        drift_detected = psi > threshold or p_value < 0.05

        drift_results.append({
            'feature': col,
            'psi': psi,
            'ks_statistic': ks_stat,
            'ks_pvalue': p_value,
            'drift_detected': drift_detected
        })

    drift_df = pd.DataFrame(drift_results)
    drift_df = drift_df.sort_values('psi', ascending=False)

    # ë“œë¦¬í”„íŠ¸ ë°œìƒ íŠ¹ì„±
    drifted_features = drift_df[drift_df['drift_detected']]

    print(f"\nì „ì²´ íŠ¹ì„±: {len(drift_df)}ê°œ")
    print(f"ë“œë¦¬í”„íŠ¸ ë°œìƒ: {len(drifted_features)}ê°œ")

    if len(drifted_features) > 0:
        print(f"\nâš ï¸  ë“œë¦¬í”„íŠ¸ ë°œìƒ íŠ¹ì„± (ìƒìœ„ 5ê°œ):")
        for i, row in drifted_features.head(5).iterrows():
            print(f"  - {row['feature']:20s}: PSI={row['psi']:.4f}, KS={row['ks_statistic']:.4f} (p={row['ks_pvalue']:.4f})")
    else:
        print(f"\nâœ“ ë“œë¦¬í”„íŠ¸ ë°œìƒ ì—†ìŒ")

    # ì‹œê°í™”
    plot_drift_summary(drift_df, output_dir, threshold)

    # CSV ì €ì¥
    drift_path = os.path.join(output_dir, 'drift_report.csv')
    drift_df.to_csv(drift_path, index=False)
    print(f"\nâœ“ ë“œë¦¬í”„íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥: {drift_path}")

    return drift_df


def plot_drift_summary(drift_df, output_dir, threshold):
    """ë“œë¦¬í”„íŠ¸ ìš”ì•½ ì‹œê°í™”"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # PSI ë¶„í¬
    ax1 = axes[0]
    drift_df_sorted = drift_df.sort_values('psi', ascending=True)
    colors = ['red' if x else 'green' for x in drift_df_sorted['drift_detected']]
    ax1.barh(range(len(drift_df_sorted)), drift_df_sorted['psi'], color=colors, alpha=0.7)
    ax1.axvline(x=threshold, color='orange', linestyle='--', linewidth=2, label=f'Threshold ({threshold})')
    ax1.set_yticks(range(len(drift_df_sorted)))
    ax1.set_yticklabels(drift_df_sorted['feature'], fontsize=8)
    ax1.set_xlabel('PSI (Population Stability Index)')
    ax1.set_title('Data Drift - PSI')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # KS í†µê³„ëŸ‰ ë¶„í¬
    ax2 = axes[1]
    drift_df_sorted = drift_df.sort_values('ks_statistic', ascending=True)
    colors = ['red' if x else 'green' for x in drift_df_sorted['drift_detected']]
    ax2.barh(range(len(drift_df_sorted)), drift_df_sorted['ks_statistic'], color=colors, alpha=0.7)
    ax2.set_yticks(range(len(drift_df_sorted)))
    ax2.set_yticklabels(drift_df_sorted['feature'], fontsize=8)
    ax2.set_xlabel('KS Statistic')
    ax2.set_title('Data Drift - KS Test')
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    output_path = os.path.join(output_dir, 'drift_summary.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

    print(f"âœ“ ë“œë¦¬í”„íŠ¸ ìš”ì•½ ì‹œê°í™” ì €ì¥: {output_path}")


def track_performance(model, X_cur, y_cur, output_dir, task_type='classification'):
    """ì„±ëŠ¥ ì¶”ì """
    print_section("ëª¨ë¸ ì„±ëŠ¥ ì¶”ì ")

    y_pred = model.predict(X_cur)

    if task_type == 'classification':
        accuracy = accuracy_score(y_cur, y_pred)
        precision = precision_score(y_cur, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_cur, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_cur, y_pred, average='weighted', zero_division=0)

        print(f"\në¶„ë¥˜ ì„±ëŠ¥:")
        print(f"  Accuracy:  {accuracy:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall:    {recall:.4f}")
        print(f"  F1-Score:  {f1:.4f}")

        metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }

    else:  # regression
        mae = mean_absolute_error(y_cur, y_pred)
        mse = mean_squared_error(y_cur, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_cur, y_pred)

        print(f"\níšŒê·€ ì„±ëŠ¥:")
        print(f"  MAE:  {mae:.4f}")
        print(f"  MSE:  {mse:.4f}")
        print(f"  RMSE: {rmse:.4f}")
        print(f"  RÂ²:   {r2:.4f}")

        metrics = {
            'mae': mae,
            'mse': mse,
            'rmse': rmse,
            'r2': r2
        }

    return metrics


def plot_prediction_distribution(model, X_ref, X_cur, output_dir):
    """ì˜ˆì¸¡ ë¶„í¬ ë¹„êµ"""
    print_section("ì˜ˆì¸¡ ë¶„í¬ ëª¨ë‹ˆí„°ë§")

    # ì˜ˆì¸¡ ìˆ˜í–‰
    if hasattr(model, 'predict_proba'):
        y_ref_pred = model.predict_proba(X_ref)[:, 1]
        y_cur_pred = model.predict_proba(X_cur)[:, 1]
        ylabel = 'Predicted Probability'
    else:
        y_ref_pred = model.predict(X_ref)
        y_cur_pred = model.predict(X_cur)
        ylabel = 'Predicted Value'

    # ì‹œê°í™”
    plt.figure(figsize=(10, 6))
    plt.hist(y_ref_pred, bins=50, alpha=0.5, label='Reference', density=True)
    plt.hist(y_cur_pred, bins=50, alpha=0.5, label='Current', density=True)
    plt.xlabel(ylabel)
    plt.ylabel('Density')
    plt.title('Prediction Distribution Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()

    output_path = os.path.join(output_dir, 'prediction_distribution.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

    print(f"âœ“ ì˜ˆì¸¡ ë¶„í¬ ì‹œê°í™” ì €ì¥: {output_path}")

    # KS í†µê³„ëŸ‰ ê³„ì‚°
    ks_stat, p_value = calculate_ks_statistic(y_ref_pred, y_cur_pred)
    print(f"  ì˜ˆì¸¡ ë¶„í¬ KS í†µê³„ëŸ‰: {ks_stat:.4f} (p={p_value:.4f})")

    if p_value < 0.05:
        print(f"  âš ï¸  ì˜ˆì¸¡ ë¶„í¬ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤!")


def generate_alerts(drift_df, metrics, output_dir, threshold=0.1):
    """ì•Œë¦¼ ìƒì„±"""
    print_section("ì•Œë¦¼ ì‹œìŠ¤í…œ")

    alerts = []

    # ë“œë¦¬í”„íŠ¸ ì•Œë¦¼
    drifted_features = drift_df[drift_df['drift_detected']]
    if len(drifted_features) > 0:
        alerts.append({
            'type': 'DATA_DRIFT',
            'severity': 'WARNING',
            'message': f'{len(drifted_features)}ê°œ íŠ¹ì„±ì—ì„œ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ë°œìƒ',
            'details': drifted_features['feature'].tolist()
        })

    # ì„±ëŠ¥ ì €í•˜ ì•Œë¦¼ (ì˜ˆì‹œ: F1 < 0.7 ë˜ëŠ” RÂ² < 0.7)
    if 'f1' in metrics and metrics['f1'] < 0.7:
        alerts.append({
            'type': 'PERFORMANCE_DEGRADATION',
            'severity': 'CRITICAL',
            'message': f'F1-Scoreê°€ ì„ê³„ê°’(0.7) ì´í•˜ì…ë‹ˆë‹¤: {metrics["f1"]:.4f}',
            'details': metrics
        })

    if 'r2' in metrics and metrics['r2'] < 0.7:
        alerts.append({
            'type': 'PERFORMANCE_DEGRADATION',
            'severity': 'CRITICAL',
            'message': f'RÂ²ê°€ ì„ê³„ê°’(0.7) ì´í•˜ì…ë‹ˆë‹¤: {metrics["r2"]:.4f}',
            'details': metrics
        })

    # ì•Œë¦¼ ì¶œë ¥
    if len(alerts) > 0:
        print(f"\nâš ï¸  {len(alerts)}ê°œ ì•Œë¦¼ ë°œìƒ:")
        for i, alert in enumerate(alerts, 1):
            print(f"\n  [{i}] {alert['severity']}: {alert['type']}")
            print(f"      {alert['message']}")
    else:
        print(f"\nâœ“ ì•Œë¦¼ ì—†ìŒ")

    # JSON ì €ì¥
    alerts_path = os.path.join(output_dir, 'alerts.json')
    with open(alerts_path, 'w', encoding='utf-8') as f:
        json.dump(alerts, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ ì•Œë¦¼ ì €ì¥: {alerts_path}")

    return alerts


def save_monitoring_report(drift_df, metrics, alerts, output_dir, model_name):
    """ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ì €ì¥"""
    report_path = os.path.join(output_dir, f"{model_name}_monitoring_report.md")

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"# ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸: {model_name}\n\n")
        f.write(f"**ìƒì„± ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        # ì•Œë¦¼
        f.write(f"## ğŸš¨ ì•Œë¦¼\n\n")
        if len(alerts) > 0:
            for alert in alerts:
                f.write(f"- **{alert['severity']}**: {alert['message']}\n")
        else:
            f.write(f"- âœ“ ì•Œë¦¼ ì—†ìŒ\n")

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        f.write(f"\n## ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­\n\n")
        for key, value in metrics.items():
            f.write(f"- **{key.upper()}**: {value:.4f}\n")

        # ë“œë¦¬í”„íŠ¸ ìš”ì•½
        f.write(f"\n## ğŸ“‰ ë°ì´í„° ë“œë¦¬í”„íŠ¸\n\n")
        drifted = drift_df[drift_df['drift_detected']]
        f.write(f"- ì „ì²´ íŠ¹ì„±: {len(drift_df)}ê°œ\n")
        f.write(f"- ë“œë¦¬í”„íŠ¸ ë°œìƒ: {len(drifted)}ê°œ\n\n")

        if len(drifted) > 0:
            f.write(f"### ë“œë¦¬í”„íŠ¸ ë°œìƒ íŠ¹ì„±\n\n")
            f.write(f"| íŠ¹ì„± | PSI | KS Statistic | p-value |\n")
            f.write(f"|------|-----|-------------|--------|\n")
            for i, row in drifted.iterrows():
                f.write(f"| {row['feature']} | {row['psi']:.4f} | {row['ks_statistic']:.4f} | {row['ks_pvalue']:.4f} |\n")

        # ì‹œê°í™”
        f.write(f"\n## ğŸ“ˆ ì‹œê°í™”\n\n")
        f.write(f"- ë“œë¦¬í”„íŠ¸ ìš”ì•½: `drift_summary.png`\n")
        f.write(f"- ì˜ˆì¸¡ ë¶„í¬: `prediction_distribution.png`\n")
        f.write(f"- ë“œë¦¬í”„íŠ¸ ìƒì„¸: `drift_report.csv`\n")

    print(f"\nâœ“ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


def main():
    parser = argparse.ArgumentParser(description='ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--model-path', type=str, required=True,
                        help='í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pkl)')
    parser.add_argument('--reference-data', type=str, required=True,
                        help='ì°¸ì¡° ë°ì´í„° ê²½ë¡œ (í•™ìŠµ ë°ì´í„°)')
    parser.add_argument('--current-data', type=str, required=True,
                        help='í˜„ì¬ ë°ì´í„° ê²½ë¡œ (í”„ë¡œë•ì…˜ ë°ì´í„°)')
    parser.add_argument('--target-column', type=str, default=None,
                        help='íƒ€ê²Ÿ ì»¬ëŸ¼ëª…')
    parser.add_argument('--task-type', type=str, choices=['classification', 'regression', 'auto'],
                        default='auto', help='íƒœìŠ¤í¬ íƒ€ì…')
    parser.add_argument('--alert-threshold', type=float, default=0.1,
                        help='ë“œë¦¬í”„íŠ¸ ì•Œë¦¼ ì„ê³„ê°’ (PSI, ê¸°ë³¸ê°’: 0.1)')
    parser.add_argument('--output-dir', type=str, default=None,
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬')

    args = parser.parse_args()

    print_header("ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output_dir:
        output_dir = args.output_dir
    else:
        current_data_path = Path(args.current_data)
        if 'projects' in current_data_path.parts:
            project_idx = current_data_path.parts.index('projects')
            project_name = current_data_path.parts[project_idx + 1]
            output_dir = f"projects/{project_name}/outputs/monitoring"
        else:
            output_dir = "outputs/monitoring"

    os.makedirs(output_dir, exist_ok=True)
    print(f"âœ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")

    # ë°ì´í„° ë¡œë“œ
    X_ref, y_ref, _ = load_data(args.reference_data, args.target_column)
    X_cur, y_cur, _ = load_data(args.current_data, args.target_column)

    # ëª¨ë¸ ë¡œë“œ
    model = load_model(args.model_path)
    model_name = Path(args.model_path).stem

    # íƒœìŠ¤í¬ íƒ€ì… ì¶”ì •
    if args.task_type == 'auto':
        if hasattr(model, 'predict_proba'):
            task_type = 'classification'
        else:
            task_type = 'regression'
        print(f"\nâœ“ ìë™ íƒœìŠ¤í¬ íƒ€ì… ê°ì§€: {task_type}")
    else:
        task_type = args.task_type

    # ë“œë¦¬í”„íŠ¸ íƒì§€
    drift_df = detect_data_drift(X_ref, X_cur, output_dir, threshold=args.alert_threshold)

    # ì˜ˆì¸¡ ë¶„í¬ ë¹„êµ
    plot_prediction_distribution(model, X_ref, X_cur, output_dir)

    # ì„±ëŠ¥ ì¶”ì  (íƒ€ê²Ÿì´ ìˆëŠ” ê²½ìš°)
    if y_cur is not None:
        metrics = track_performance(model, X_cur, y_cur, output_dir, task_type)
    else:
        print("\nâš ï¸  íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ì—†ì–´ ì„±ëŠ¥ ì¶”ì ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        metrics = {}

    # ì•Œë¦¼ ìƒì„±
    alerts = generate_alerts(drift_df, metrics, output_dir, threshold=args.alert_threshold)

    # ë¦¬í¬íŠ¸ ì €ì¥
    save_monitoring_report(drift_df, metrics, alerts, output_dir, model_name)

    print_header("ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")
    print(f"\nğŸ“ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_dir}/")
    print(f"   - ì‹œê°í™”: *.png")
    print(f"   - ë¦¬í¬íŠ¸: {model_name}_monitoring_report.md")
    print(f"   - ë“œë¦¬í”„íŠ¸: drift_report.csv")
    print(f"   - ì•Œë¦¼: alerts.json")

    return 0


if __name__ == '__main__':
    sys.exit(main())
