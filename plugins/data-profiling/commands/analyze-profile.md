---
name: analyze-profile
description: í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë°ì´í„° ì „ì²˜ë¦¬, ì¶”ê°€ ë¶„ì„, ëª¨ë¸ë§ ì§€ì¹¨ì´ ë‹´ê¸´ EDA ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
arguments:
  - name: profile-path
    description: í”„ë¡œíŒŒì¼ë§ HTML ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
    required: true
  - name: data-path
    description: ì›ë³¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì¶”ê°€ ë¶„ì„ìš©)
    required: true
  - name: target-column
    description: íƒ€ê²Ÿ ë³€ìˆ˜ ì»¬ëŸ¼ëª…
    required: false
  - name: output-format
    description: ì¶œë ¥ í˜•ì‹ (markdown, pdf)
    required: false
    default: "markdown"
  - name: output-dir
    description: ë¦¬í¬íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬
    required: false
    default: "projects/{project-name}/outputs/reports"
---

# /analyze-profile

í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ë°ì´í„° ì „ì²˜ë¦¬, ì¶”ê°€ ë¶„ì„, ëª¨ë¸ë§ ì§€ì¹¨ì„ ë‹´ì€ A4 í•œ ì¥ ë¶„ëŸ‰ì˜ EDA ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## Usage

```bash
# ê¸°ë³¸ ì‚¬ìš©ë²•
/analyze-profile \
  --profile-path "projects/creditcard-fraud-detection/outputs/reports/creditcard_profile_report.html" \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv"

# íƒ€ê²Ÿ ì»¬ëŸ¼ ì§€ì •
/analyze-profile \
  --profile-path "projects/creditcard-fraud-detection/outputs/reports/creditcard_profile_report.html" \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class"

# PDF í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
/analyze-profile \
  --profile-path "projects/creditcard-fraud-detection/outputs/reports/creditcard_profile_report.html" \
  --data-path "projects/creditcard-fraud-detection/data/raw/creditcard.csv" \
  --target-column "Class" \
  --output-format pdf
```

## What This Command Does

### 1. í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ ë¶„ì„
- HTML ë¦¬í¬íŠ¸ì—ì„œ ì£¼ìš” í†µê³„ ì •ë³´ ì¶”ì¶œ
- Alerts ì„¹ì…˜ ë¶„ì„ (ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ)
- ë³€ìˆ˜ë³„ ë¶„í¬ íŠ¹ì„± íŒŒì•…
- ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ë¶„ì„

### 2. ì›ë³¸ ë°ì´í„° ì¶”ê°€ ë¶„ì„
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì •ëŸ‰í™”
- ì´ìƒì¹˜ íƒì§€ ë° ì˜í–¥ë„ í‰ê°€
- ë³€ìˆ˜ ê°„ ê´€ê³„ ì‹¬ì¸µ ë¶„ì„
- ì‹œê³„ì—´ íŒ¨í„´ í™•ì¸ (í•´ë‹¹ë˜ëŠ” ê²½ìš°)

### 3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì§€ì¹¨ ìƒì„±
ë‹¤ìŒ 3ê°€ì§€ ê´€ì ì—ì„œ êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œ ì œì‹œ:

#### ğŸ“‹ ë°ì´í„° ì „ì²˜ë¦¬ ê´€ì 
- ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ (Imputation, Deletion)
- ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ë²• (Capping, Transformation, Removal)
- ìŠ¤ì¼€ì¼ë§ ì „ëµ (StandardScaler, MinMaxScaler, RobustScaler)
- ì¸ì½”ë”© ì „ëµ (One-hot, Label, Target encoding)
- ë°ì´í„° íƒ€ì… ë³€í™˜

#### ğŸ” ì¶”ê°€ ë¶„ì„ ê´€ì 
- ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš© íƒìƒ‰
- íŒŒìƒ ë³€ìˆ˜ ìƒì„± ì•„ì´ë””ì–´
- ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„ì„ (íƒ€ê²Ÿë³„, ì¹´í…Œê³ ë¦¬ë³„)
- ì‹œê³„ì—´ ë¶„í•´ (Trend, Seasonality, Residual)
- ë‹¤ë³€ëŸ‰ ë¶„ì„ (PCA, t-SNE)

#### ğŸ¤– ëª¨ë¸ë§ ê´€ì 
- ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ ì¶”ì²œ (ë¶„ë¥˜/íšŒê·€/í´ëŸ¬ìŠ¤í„°ë§)
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ì „ëµ (SMOTE, Undersampling, Class weights)
- Feature selection ë°©ë²•
- êµì°¨ ê²€ì¦ ì „ëµ
- í‰ê°€ ì§€í‘œ ì„ ì • (Accuracy, Precision, Recall, F1, ROC-AUC)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìš°ì„ ìˆœìœ„

### 4. A4 í•œ ì¥ ë¶„ëŸ‰ ë ˆí¬íŠ¸ ìƒì„±
- **íŒŒì¼ëª…**: `{dataset_name}_eda_report.md` (ë˜ëŠ” `.pdf`)
- **ìœ„ì¹˜**: `projects/{project-name}/outputs/reports/`
- **êµ¬ì¡°**:
  - Executive Summary (í•µì‹¬ ìš”ì•½)
  - ë°ì´í„° ê°œìš”
  - ì£¼ìš” ë°œê²¬ì‚¬í•­
  - ë°ì´í„° ì „ì²˜ë¦¬ ì§€ì¹¨
  - ì¶”ê°€ ë¶„ì„ ê¶Œê³ ì‚¬í•­
  - ëª¨ë¸ë§ ì „ëµ
  - ë‹¤ìŒ ë‹¨ê³„ (Next Steps)

## Output Structure

### Markdown ë¦¬í¬íŠ¸ ì˜ˆì‹œ

```markdown
# EDA ë¶„ì„ ë¦¬í¬íŠ¸: ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° íƒì§€

**ìƒì„±ì¼**: 2026-01-31
**ë¶„ì„ ëŒ€ìƒ**: creditcard.csv (284,807ê±´)

---

## ğŸ“Š Executive Summary

- **ì£¼ìš” ê³¼ì œ**: ê·¹ì‹¬í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜• (1:578)
- **í•µì‹¬ ë°œê²¬**: Amount ë³€ìˆ˜ ìŠ¤ì¼€ì¼ ì°¨ì´, Time ë³€ìˆ˜ í™œìš© ê°€ëŠ¥
- **ìš°ì„  ì¡°ì¹˜**: SMOTE + RobustScaler + XGBoost ì¡°í•© ê¶Œì¥
- **ì˜ˆìƒ ì„±ëŠ¥**: F1-Score 0.85+ ë‹¬ì„± ê°€ëŠ¥

---

## ğŸ“‹ ë°ì´í„° ê°œìš”

| í•­ëª© | ê°’ |
|------|-----|
| ì „ì²´ ê±´ìˆ˜ | 284,807ê±´ |
| íŠ¹ì„± ê°œìˆ˜ | 31ê°œ (Time, V1-V28, Amount, Class) |
| ê²°ì¸¡ì¹˜ | 0ê°œ |
| ì¤‘ë³µ | 0ê±´ |
| ë©”ëª¨ë¦¬ | 67.4 MB |

**íƒ€ê²Ÿ ë¶„í¬**:
- ì •ìƒ ê±°ë˜: 284,315ê±´ (99.83%)
- ì‚¬ê¸° ê±°ë˜: 492ê±´ (0.17%)
- ë¶ˆê· í˜• ë¹„ìœ¨: **1:578** âš ï¸

---

## ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­

### 1. í´ë˜ìŠ¤ ë¶ˆê· í˜• (Critical)
- ì‚¬ê¸° ê±°ë˜ê°€ ì „ì²´ì˜ 0.17%ì— ë¶ˆê³¼
- Accuracy ì§€í‘œëŠ” ë¬´ì˜ë¯¸ (ëª¨ë‘ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡í•´ë„ 99.83%)
- Precision-Recall ê³¡ì„  ì¤‘ì‹¬ì˜ í‰ê°€ í•„ìš”

### 2. ë³€ìˆ˜ ìŠ¤ì¼€ì¼ ì°¨ì´
- Amount: 0 ~ 25,691 (í‰ê·  88.3, í‘œì¤€í¸ì°¨ 250.1)
- V1-V28: PCA ë³€í™˜ë¨ (í‘œì¤€í™”ëœ ë²”ìœ„)
- **ìŠ¤ì¼€ì¼ ì°¨ì´**: ìµœëŒ€/ìµœì†Œ = 1,143,543ë°°

### 3. PCA ë³€í™˜ëœ íŠ¹ì„±
- V1-V28ì€ ì›ë³¸ íŠ¹ì„±ëª… ë¶ˆëª…
- ì§ì ‘ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ ì–´ë ¤ì›€
- Feature importance ë¶„ì„ìœ¼ë¡œ ì¤‘ìš” ë³€ìˆ˜ ì‹ë³„ í•„ìš”

### 4. ì‹œê°„ ì •ë³´
- Time: ì²« ê±°ë˜ ì´í›„ ê²½ê³¼ ì‹œê°„(ì´ˆ)
- 0 ~ 172,792ì´ˆ (ì•½ 48ì‹œê°„)
- ì‹œê°„ëŒ€ë³„ ì‚¬ê¸° íŒ¨í„´ ì¡´ì¬ ê°€ëŠ¥ì„±

---

## ğŸ“‹ ë°ì´í„° ì „ì²˜ë¦¬ ì§€ì¹¨

### 1. ìŠ¤ì¼€ì¼ë§ (Priority: High)
```python
from sklearn.preprocessing import RobustScaler

# Amount ë³€ìˆ˜ë§Œ ìŠ¤ì¼€ì¼ë§ (V1-V28ì€ ì´ë¯¸ ì •ê·œí™”ë¨)
scaler = RobustScaler()  # ì´ìƒì¹˜ì— ê°•ê±´
X['Amount_scaled'] = scaler.fit_transform(X[['Amount']])
X = X.drop('Amount', axis=1)
```

**ì„ íƒ ì´ìœ **:
- RobustScaler: ì´ìƒì¹˜ ì˜í–¥ ìµœì†Œí™” (Amountì— ê·¹ë‹¨ê°’ ì¡´ì¬)
- V1-V28ì€ ì´ë¯¸ PCAë¡œ í‘œì¤€í™”ë˜ì–´ ì¶”ê°€ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”

### 2. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
```python
# Timeì„ ì‹œê°„ëŒ€ë¡œ ë³€í™˜
X['Hour'] = (X['Time'] / 3600) % 24
X['Day'] = (X['Time'] / 86400).astype(int)

# ì£¼ê¸°ì„± ì¸ì½”ë”© (Cyclical encoding)
import numpy as np
X['Hour_sin'] = np.sin(2 * np.pi * X['Hour'] / 24)
X['Hour_cos'] = np.cos(2 * np.pi * X['Hour'] / 24)
```

### 3. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (Priority: Critical)

**ì˜µì…˜ A: SMOTE (ê¶Œì¥)**
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(sampling_strategy=0.1, random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)
```

**ì˜µì…˜ B: Class weights**
```python
from sklearn.ensemble import RandomForestClassifier

# ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°
scale_pos_weight = (y == 0).sum() / (y == 1).sum()  # 578

model = RandomForestClassifier(
    class_weight='balanced',  # ë˜ëŠ” {0: 1, 1: 578}
    random_state=42
)
```

**ê¶Œì¥**: SMOTE + Class weights ì¡°í•©

---

## ğŸ” ì¶”ê°€ ë¶„ì„ ê¶Œê³ ì‚¬í•­

### 1. Feature Importance ë¶„ì„
```python
# XGBoostë¡œ ë³€ìˆ˜ ì¤‘ìš”ë„ íŒŒì•…
import xgboost as xgb

model = xgb.XGBClassifier(scale_pos_weight=578)
model.fit(X_train, y_train)

# ìƒìœ„ 10ê°œ ì¤‘ìš” ë³€ìˆ˜ ì‹œê°í™”
xgb.plot_importance(model, max_num_features=10)
```

**ëª©ì **: V1-V28 ì¤‘ ì–´ë–¤ ë³€ìˆ˜ê°€ ì‚¬ê¸° íƒì§€ì— ì¤‘ìš”í•œì§€ íŒŒì•…

### 2. ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„
```python
# ì‹œê°„ëŒ€ë³„ ì‚¬ê¸° ë¹„ìœ¨ ë¶„ì„
fraud_by_hour = df.groupby('Hour')['Class'].mean()
fraud_by_hour.plot(kind='bar', title='Fraud Rate by Hour')
```

**ê°€ì„¤**: íŠ¹ì • ì‹œê°„ëŒ€(ì‹¬ì•¼)ì— ì‚¬ê¸° ê±°ë˜ ì§‘ì¤‘ ê°€ëŠ¥ì„±

### 3. Amount ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„ì„
```python
# ê¸ˆì•¡ëŒ€ë³„ ì‚¬ê¸° ë¹„ìœ¨
df['Amount_bin'] = pd.cut(df['Amount'], bins=[0, 10, 50, 100, 500, np.inf])
df.groupby('Amount_bin')['Class'].mean()
```

### 4. SHAP ë¶„ì„ (ëª¨ë¸ í•™ìŠµ í›„)
```python
import shap

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test)
```

**ëª©ì **: ì‚¬ê¸° ì˜ˆì¸¡ì— ê¸°ì—¬í•˜ëŠ” ë³€ìˆ˜ì™€ ë°©í–¥ì„± ì´í•´

---

## ğŸ¤– ëª¨ë¸ë§ ì „ëµ

### 1. ì•Œê³ ë¦¬ì¦˜ ì„ íƒ

**ì¶”ì²œ ìˆœìœ„**:
1. **XGBoost** (1ìˆœìœ„)
   - ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ ê°•ì  (`scale_pos_weight`)
   - Feature importance ì œê³µ
   - ë†’ì€ ì„±ëŠ¥

2. **LightGBM** (2ìˆœìœ„)
   - XGBoostë³´ë‹¤ ë¹ ë¦„
   - ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ìœ¨ì 

3. **Random Forest** (ë² ì´ìŠ¤ë¼ì¸)
   - í•´ì„ ê°€ëŠ¥
   - ì•ˆì •ì  ì„±ëŠ¥

**ë¹„ì¶”ì²œ**: Logistic Regression (ì„ í˜• ê´€ê³„ ê°€ì •, ë¶ˆê· í˜• ì·¨ì•½)

### 2. í‰ê°€ ì§€í‘œ

**ì ˆëŒ€ ê¸ˆì§€**: Accuracy (99.83% ë¶ˆê· í˜•)

**ê¶Œì¥ ì§€í‘œ**:
- **Precision**: False Positive ë¹„ìš© ì¤‘ìš” ì‹œ
- **Recall**: False Negative ë¹„ìš© ì¤‘ìš” ì‹œ (ì‚¬ê¸° ë†“ì¹˜ë©´ ì†ì‹¤)
- **F1-Score**: Precision-Recall ê· í˜•
- **PR-AUC**: ë¶ˆê· í˜• ë°ì´í„° ìµœì  (ROC-AUCë³´ë‹¤ ìœ ë¦¬)

**ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì **:
- FN(ì‚¬ê¸°ë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤íŒ) > FP(ì •ìƒì„ ì‚¬ê¸°ë¡œ ì˜¤íŒ)
- Recall ìš°ì„ , ë‹¨ Precision ìµœì†Œ 0.8 ì´ìƒ ìœ ì§€

### 3. êµì°¨ ê²€ì¦

```python
from sklearn.model_selection import StratifiedKFold

# í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©° 5-fold CV
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for train_idx, val_idx in cv.split(X, y):
    X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]
    y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]
    # í•™ìŠµ ë° í‰ê°€
```

### 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)

```python
import optuna

def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'scale_pos_weight': 578,
    }
    model = xgb.XGBClassifier(**params)
    # ... í•™ìŠµ ë° í‰ê°€
    return f1_score  # ìµœì í™” ëª©í‘œ

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)
```

### 5. Threshold ìµœì í™”

```python
from sklearn.metrics import precision_recall_curve

# ìµœì  ì„ê³„ê°’ ì°¾ê¸°
precision, recall, thresholds = precision_recall_curve(y_val, y_proba)
f1_scores = 2 * (precision * recall) / (precision + recall)
optimal_threshold = thresholds[np.argmax(f1_scores)]

# ì˜ˆì¸¡ ì‹œ ì ìš©
y_pred = (y_proba >= optimal_threshold).astype(int)
```

---

## ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„ (Next Steps)

### ìš°ì„ ìˆœìœ„ 1 (ì¦‰ì‹œ ì‹¤í–‰)
- [ ] `/engineer-features`: Amount ìŠ¤ì¼€ì¼ë§, Time íŠ¹ì„± ì¶”ì¶œ
- [ ] `/handle-imbalance`: SMOTE ì ìš© (sampling_strategy=0.1)
- [ ] `/train-models`: XGBoost ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ

### ìš°ì„ ìˆœìœ„ 2 (ëª¨ë¸ í•™ìŠµ í›„)
- [ ] Feature importance ë¶„ì„ â†’ ìƒìœ„ 20ê°œ ë³€ìˆ˜ ì„ íƒ
- [ ] SHAP ë¶„ì„ â†’ ì‚¬ê¸° íŒ¨í„´ ì´í•´
- [ ] Threshold ìµœì í™” â†’ Recall 0.9, Precision 0.8 ëª©í‘œ

### ìš°ì„ ìˆœìœ„ 3 (ì„±ëŠ¥ ê°œì„ )
- [ ] Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- [ ] Ensemble (XGBoost + LightGBM + RF)
- [ ] ì‹œê°„ëŒ€ë³„ ëª¨ë¸ (ì‹¬ì•¼ vs ì£¼ê°„)

---

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥

| ëª¨ë¸ | ì˜ˆìƒ F1-Score | ì˜ˆìƒ PR-AUC |
|------|--------------|------------|
| Baseline (Logistic) | 0.65 | 0.70 |
| Random Forest + SMOTE | 0.80 | 0.85 |
| **XGBoost + SMOTE** | **0.85-0.90** | **0.90-0.95** |
| Ensemble | 0.90+ | 0.95+ |

**ê·¼ê±°**: Kaggle ë²¤ì¹˜ë§ˆí¬ ì°¸ì¡° (ë™ì¼ ë°ì´í„°ì…‹)

---

**ìƒì„±ì¼**: 2026-01-31
**ë¶„ì„ ë„êµ¬**: ydata-profiling v4.18.1
**ë‹¤ìŒ ì»¤ë§¨ë“œ**: `/engineer-features`, `/handle-imbalance`, `/train-models`
```

---

## Related Commands

- `/profile-data`: ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ ìƒì„±
- `/engineer-features`: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
- `/handle-imbalance`: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
- `/train-models`: ëª¨ë¸ í•™ìŠµ

## Agents Used

- `eda-analyst` (í•„ìˆ˜): í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ ì‹¬ì¸µ ë¶„ì„

## Notes

âš ï¸ **ì£¼ì˜ì‚¬í•­**:
- HTML ë¦¬í¬íŠ¸ê°€ ë¨¼ì € ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•¨ (`/profile-data` ì‹¤í–‰ í•„ìš”)
- PDF ì¶œë ¥ì€ pandoc ì„¤ì¹˜ í•„ìš”: `brew install pandoc`

ğŸ’¡ **íŒ**:
- ì´ ë ˆí¬íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬ ìš°ì„ ìˆœìœ„ ê²°ì •
- ì½”ë“œ ìŠ¤ë‹ˆí«ì„ ë³µì‚¬í•˜ì—¬ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
- ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ í‰ê°€ì§€í‘œ ì¡°ì •
