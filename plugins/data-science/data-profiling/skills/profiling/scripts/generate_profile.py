#!/usr/bin/env python3
"""
ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ìŠ¤í¬ë¦½íŠ¸

ydata-profilingì„ ì‚¬ìš©í•˜ì—¬ ìë™í™”ëœ EDA ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³  ë¸Œë¼ìš°ì €ì—ì„œ ì—½ë‹ˆë‹¤.

ì„¤ì¹˜:
    # uv ì‚¬ìš© (ê¶Œì¥ - 10-100ë°° ë¹ ë¦„)
    cd plugins/data-profiling/skills/profiling
    uv pip install -r requirements.txt

    # ë˜ëŠ” pip ì‚¬ìš©
    pip install -r requirements.txt

ì‚¬ìš©ë²•:
    python generate_profile.py --data-path "./data/raw/creditcard.csv" --target-column "Class"
    python generate_profile.py --data-path "./data.csv" --sample-size 50000 --mode minimal

í•„ìš” íŒ¨í‚¤ì§€:
    - pandas
    - ydata-profiling
"""

import argparse
import os
import platform
import subprocess
import sys
from pathlib import Path

import numpy as np
import pandas as pd


def open_in_browser(filepath):
    """ìš´ì˜ì²´ì œì— ë§ê²Œ ë¸Œë¼ìš°ì €ì—ì„œ HTML íŒŒì¼ ì—´ê¸°"""
    system = platform.system()
    abs_path = os.path.abspath(filepath)

    try:
        if system == 'Darwin':  # macOS
            subprocess.run(['open', abs_path], check=True)
        elif system == 'Linux':
            subprocess.run(['xdg-open', abs_path], check=True)
        elif system == 'Windows':
            os.startfile(abs_path)
        else:
            print(f"âš ï¸  ìë™ ë¸Œë¼ìš°ì € ì˜¤í”ˆì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìš´ì˜ì²´ì œì…ë‹ˆë‹¤: {system}")
            print(f"   ìˆ˜ë™ìœ¼ë¡œ ì—´ê¸°: {abs_path}")
            return False
        return True
    except Exception as e:
        print(f"âš ï¸  ë¸Œë¼ìš°ì € ìë™ ì˜¤í”ˆ ì‹¤íŒ¨: {e}")
        print(f"   ìˆ˜ë™ìœ¼ë¡œ ì—´ê¸°: {abs_path}")
        return False


def load_data(data_path, sample_size=None):
    """ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°ì´í„° íŒŒì¼ ë¡œë“œ"""
    file_ext = Path(data_path).suffix.lower()

    print(f"\në°ì´í„° ë¡œë“œ ì¤‘: {data_path}")

    # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ë¡œë“œ
    if file_ext == '.csv':
        df = pd.read_csv(data_path)
    elif file_ext in ['.xlsx', '.xls']:
        df = pd.read_excel(data_path)
    elif file_ext == '.parquet':
        df = pd.read_parquet(data_path)
    elif file_ext == '.json':
        df = pd.read_json(data_path)
    elif file_ext == '.feather':
        df = pd.read_feather(data_path)
    elif file_ext in ['.h5', '.hdf5']:
        df = pd.read_hdf(data_path)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")

    # ìƒ˜í”Œë§ (ì§€ì •ëœ ê²½ìš°)
    if sample_size and len(df) > sample_size:
        print(f"âš ï¸  ìƒ˜í”Œë§: {len(df):,}ê±´ â†’ {sample_size:,}ê±´")
        df = df.sample(n=sample_size, random_state=42)

    print(f"âœ“ ì™„ë£Œ: {len(df):,}ê±´, {len(df.columns)}ê°œ ì»¬ëŸ¼")
    return df


def print_basic_info(df, target_column=None):
    """ê¸°ë³¸ ì •ë³´ ì¶œë ¥"""
    print(f"\n{'â”€' * 60}")
    print("ê¸°ë³¸ ì •ë³´")
    print(f"{'â”€' * 60}")

    print(f"\nì „ì²´ í–‰ ìˆ˜: {len(df):,}ê±´")
    print(f"ì „ì²´ ì—´ ìˆ˜: {len(df.columns)}ê°œ")
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    print(f"ê²°ì¸¡ì¹˜: {df.isnull().sum().sum():,}ê°œ")

    # íƒ€ê²Ÿ ì»¬ëŸ¼ ì •ë³´ (ë¶„ë¥˜ ë¬¸ì œì¸ ê²½ìš°)
    if target_column and target_column in df.columns:
        print(f"\níƒ€ê²Ÿ ì»¬ëŸ¼: {target_column}")

        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        if df[target_column].dtype in ['int64', 'int32', 'object', 'category']:
            value_counts = df[target_column].value_counts()
            print(f"í´ë˜ìŠ¤ ë¶„í¬:")
            for cls, count in value_counts.items():
                pct = count / len(df) * 100
                print(f"  í´ë˜ìŠ¤ {cls}: {count:,}ê±´ ({pct:.2f}%)")

            # ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°
            if len(value_counts) == 2:
                majority = value_counts.max()
                minority = value_counts.min()
                imbalance_ratio = majority / minority
                print(f"  ë¶ˆê· í˜• ë¹„ìœ¨: 1:{imbalance_ratio:.0f}")


def generate_profile_report(df, output_path, mode='explorative', title=None):
    """ydata-profilingì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œíŒŒì¼ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        from ydata_profiling import ProfileReport
    except ImportError:
        try:
            from pandas_profiling import ProfileReport
            print("âš ï¸  pandas_profilingì€ deprecatedë˜ì—ˆìŠµë‹ˆë‹¤. ydata-profilingìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì„¸ìš”.")
            print("   pip install ydata-profiling")
        except ImportError:
            print("\nâŒ ì—ëŸ¬: ydata-profilingì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜ ëª…ë ¹ì–´: pip install ydata-profiling")
            sys.exit(1)

    print(f"\n{'â”€' * 60}")
    print("í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    print(f"{'â”€' * 60}")
    print(f"ëª¨ë“œ: {mode}")
    print("â³ ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")

    # ëª¨ë“œì— ë”°ë¥¸ ì„¤ì •
    if mode == 'minimal':
        minimal = True
        explorative = False
    elif mode == 'explorative':
        minimal = False
        explorative = True
    else:  # default
        minimal = False
        explorative = False

    # í”„ë¡œíŒŒì¼ ìƒì„±
    profile = ProfileReport(
        df,
        title=title or "Data Profiling Report",
        minimal=minimal,
        explorative=explorative
    )

    # HTML ì €ì¥
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    profile.to_file(output_path)

    print(f"\nâœ“ ì™„ë£Œ!")
    print(f"ğŸ“Š ë¦¬í¬íŠ¸ ì €ì¥ ìœ„ì¹˜: {output_path}")

    return output_path


def print_summary_recommendations(df, target_column=None):
    """ì£¼ìš” ë°œê²¬ì‚¬í•­ ë° ê¶Œê³ ì‚¬í•­ ì¶œë ¥"""
    print(f"\n{'â”€' * 60}")
    print("âš ï¸  ì£¼ìš” ë°œê²¬ì‚¬í•­ ë° ê¶Œê³ ì‚¬í•­")
    print(f"{'â”€' * 60}")

    # ê²°ì¸¡ì¹˜ í™•ì¸
    missing_counts = df.isnull().sum()
    missing_cols = missing_counts[missing_counts > 0]
    if len(missing_cols) > 0:
        missing_pct = (missing_counts.sum() / (len(df) * len(df.columns))) * 100
        print(f"\nâš ï¸  ê²°ì¸¡ì¹˜: {missing_pct:.2f}% ({len(missing_cols)}ê°œ ì»¬ëŸ¼)")
        print("   ê¶Œê³ : /engineer-featuresë¡œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬")

    # í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸ (íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
    if target_column and target_column in df.columns:
        value_counts = df[target_column].value_counts()
        if len(value_counts) == 2:
            majority = value_counts.max()
            minority = value_counts.min()
            imbalance_ratio = majority / minority
            if imbalance_ratio > 10:
                print(f"\nâš ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜•: 1:{imbalance_ratio:.0f}")
                print("   ê¶Œê³ : /handle-imbalanceë¡œ ë¶ˆê· í˜• ì²˜ë¦¬ (SMOTE, Undersampling)")

    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ ì°¨ì´ í™•ì¸
    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
    if len(numeric_cols) > 1:
        scales = df[numeric_cols].std()
        if scales.max() / scales.min() > 100:
            print(f"\nâš ï¸  ë³€ìˆ˜ ê°„ ìŠ¤ì¼€ì¼ ì°¨ì´ê°€ í½ë‹ˆë‹¤ (ìµœëŒ€/ìµœì†Œ = {scales.max() / scales.min():.0f}ë°°)")
            print("   ê¶Œê³ : /engineer-featuresë¡œ ìŠ¤ì¼€ì¼ë§ (StandardScaler, MinMaxScaler)")

    # ìƒê´€ê´€ê³„ í™•ì¸
    if len(numeric_cols) > 1:
        corr_matrix = df[numeric_cols].corr().abs()
        # ëŒ€ê°ì„  ì œì™¸í•˜ê³  ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°
        corr_matrix = corr_matrix.where(
            ~np.triu(np.ones(corr_matrix.shape)).astype(bool)
        )
        high_corr = corr_matrix[corr_matrix > 0.9].stack()
        if len(high_corr) > 0:
            print(f"\nâš ï¸  ë†’ì€ ìƒê´€ê´€ê³„ (>0.9): {len(high_corr)}ê°œ ë³€ìˆ˜ ìŒ")
            print("   ê¶Œê³ : ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œ ê°€ëŠ¥ - ë³€ìˆ˜ ì œê±° ê³ ë ¤")

    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   /engineer-features: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ë° ì „ì²˜ë¦¬")
    if target_column:
        print("   /handle-imbalance: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬")
    print("   /train-models: ëª¨ë¸ í•™ìŠµ")


def main():
    parser = argparse.ArgumentParser(
        description='ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ë° ìë™í™”ëœ EDA ë¦¬í¬íŠ¸ ìƒì„±',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš©ë²•
  python generate_profile.py --data-path "./data/raw/creditcard.csv"

  # íƒ€ê²Ÿ ì»¬ëŸ¼ ì§€ì •
  python generate_profile.py --data-path "./data.csv" --target-column "Class"

  # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒ˜í”Œë§
  python generate_profile.py --data-path "./data.csv" --sample-size 50000 --mode minimal

  # ë¸Œë¼ìš°ì € ìë™ ì˜¤í”ˆ ë¹„í™œì„±í™”
  python generate_profile.py --data-path "./data.csv" --no-browser
        """
    )

    parser.add_argument(
        '--data-path',
        type=str,
        required=True,
        help='ë¶„ì„í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ (CSV, Excel, Parquet ë“±)'
    )
    parser.add_argument(
        '--target-column',
        type=str,
        help='íƒ€ê²Ÿ ë³€ìˆ˜ ì»¬ëŸ¼ëª… (ë¶„ë¥˜/íšŒê·€ ë¬¸ì œì¸ ê²½ìš°)'
    )
    parser.add_argument(
        '--sample-size',
        type=int,
        help='ìƒ˜í”Œë§ í¬ê¸° (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì¸ ê²½ìš°)'
    )
    parser.add_argument(
        '--mode',
        type=str,
        choices=['minimal', 'default', 'explorative'],
        default='explorative',
        help='í”„ë¡œíŒŒì¼ë§ ëª¨ë“œ (ê¸°ë³¸ê°’: explorative)'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default='outputs/reports',
        help='ë¦¬í¬íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: outputs/reports)'
    )
    parser.add_argument(
        '--no-browser',
        action='store_true',
        help='ë¸Œë¼ìš°ì € ìë™ ì˜¤í”ˆ ë¹„í™œì„±í™”'
    )

    args = parser.parse_args()

    # í—¤ë” ì¶œë ¥
    print("=" * 60)
    print("ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ì‹œì‘")
    print("=" * 60)

    # ë°ì´í„° ë¡œë“œ
    df = load_data(args.data_path, args.sample_size)

    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
    memory_mb = df.memory_usage(deep=True).sum() / 1024**2
    print(f"âœ“ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f} MB")

    # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
    print_basic_info(df, args.target_column)

    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    dataset_name = Path(args.data_path).stem
    output_filename = f"{dataset_name}_profile_report.html"
    output_path = Path(args.output_dir) / output_filename

    # í”„ë¡œíŒŒì¼ ë¦¬í¬íŠ¸ ìƒì„±
    report_path = generate_profile_report(
        df,
        output_path,
        mode=args.mode,
        title=f"Data Profiling Report: {dataset_name}"
    )

    # ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°
    if not args.no_browser:
        print("\nğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ ë¦¬í¬íŠ¸ë¥¼ ì—¬ëŠ” ì¤‘...")
        success = open_in_browser(report_path)
        if success:
            print("âœ“ ë¸Œë¼ìš°ì €ì—ì„œ ë¦¬í¬íŠ¸ê°€ ì—´ë ¸ìŠµë‹ˆë‹¤.")
    else:
        print(f"\nìˆ˜ë™ìœ¼ë¡œ ì—´ê¸°: {report_path.absolute()}")

    # ìš”ì•½ ë° ê¶Œê³ ì‚¬í•­
    print_summary_recommendations(df, args.target_column)

    print(f"\n{'=' * 60}")
    print("í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
